= Лекция 13 

Почему когда мы решаем эту задачу мы используем то представление, которое использовалось в ИОМК? 

$ u(x,y) = sum^k_(i = 0) h_i(x) g_i(y) $

Любому человеку понятно, что это не самое общее представление функции от двух переменных. Вообще говоря общее представление -- функция от $n$ переменных.

Это подводит нас к теореме Колмогорова-Арнольда и ее применении при решении нелинейных уравнений в частных производных. 

Вопрос о представлении функции многих переменных через суперпозицию функции одной переменной составляет существо 13-ой проблемы Гильберта: в самом начале 20 века Девид Гильберт сформулировал 25 проблем, самых сложных проблем в чистой прикладной математике на тот момент времени. Три из них не решены до сих пор. Еще несколько переформулированы таким образом, чтобы быть более трактуемыми в формальных математических терминов. Однако для 13-ой проблемы решение было найдено нашими соотечественниками Андреем Николаевичем Колмогоровым и его учеником Владимиром Игоревичем Арнольдом. Оно выражается в знаменитой теореме Колмогорова-Арнольда (KST, Kolmogorov Superposotion Theorem), которая гласит следующее:

Всякая непрерывная функция $n$ переменных представима в виде:

$ u(x_1, dots, x_n) = sum_(i = 1)^(2n + 1) chi_i (sum_(j = 1)^n phi_(i j)(x_i)) $

Где $chi_i$ и ... представляют собой непрерывные функции одной переменной. На вопрос Гильберта был дан положительный ответ, причем ответ удивительный. Во-первых, следует подчеркнуть, что в формулировке теоремы Колмогорова-Арнольда фигурирует точное равенство (не апроксимация). Необходимое число функций весьма мало. Необходимое число внутренних функций -- число переменных ($n$). Для функции от двух переменных это число 2. Внешних функций требуется $2n + 1$. В рамках этой теоремы Колмогорова-Арнольда показали, что внутренние функции могут быть одинаковыми для всех непрерывных функций $u$. А вот внешние функции $chi_i$ уже специфичны для функции $u$, представление которой мы ищем. 

#pagebreak()
Указанное представление является предельно сильным. И породило гигантское количество всевозможных приложений. В частности, следствие из теоремы Колмогорова:

$ u(x_1, dots, x_n) = sum_(i = 1)^(2n + 1) chi_i (sum_(j = 1)^n d_(i j) phi_(j)(x_i)) $

..............

Такое представление является основой всех нейросетевых представлений. Формально мы здесь показали, что мы можем построить нейронную сеть, которая состоит всего лишь из двух слоев. Нам нужно только лишь выбрать в качестве функции активации внутреннего слоя функции $phi_j$, а в качестве функции активации внешнего слоя функции $chi_i$. Тогда обучив нейронную сеть таким образом, чтобы веса, ведущие от первого слоя ко второму были в точности равны этим Колмогоровским коэфициентам ....

Мы получаем ....

Соответствующие утверждение появилось на заре нейронных сетей, носит название теоремы Hecht-Nielsen, сейчас это тренд в нейронных сетях, им активно занимаются. Называются KAN сети, Kolmogorov-Arnold's Networks.
//Забыли о теореме Хеч-Нилсон на 30 лет, сейчас стала трендом.

Возвращаясь от нейронных сетей к теореме Колмогорова-Арнольда, практической ... сдерживалось двумя обстоятельствами:

1) В оригинальном доказательстве Колмогорова существование как внутренних так и внешних функций просто доказывалось, но мы не имели представления о том, как их реально строить. Но это только половина беды. 

2) Внутренние, да и внешние, функции представляли собой специфический математический объект. Они были всюду непрерывны, но нигде не дифференцируемы. В математике такого рода функции носят названия Чертовых Лестниц, devil's staircase. 

Первая проблема была решена уже в 60-х годах прошлого века. Советско-американский математик David Scprecher построил алгоритм построения внутренних функций в явном виде. 
//Позже Knoppen нашел ошибку.
#pagebreak()
Однако гораздо более сильным результатом в этом направлении были результаты шведского математика Хедберга, который показал, что представление Колмогорова-Арнольда имеет место не только для тех конкретных функций, которые доказал Колмогоров, но для весьма большого числа функций, из пространства $C[0, 1]$. Те функции, для которых это верно, они "плотны" в множестве всех непрерывных функций. С практической точки зрения это значит, что если вы берете функцию $phi$, то если вам удастся найти функцию $chi$, то вы получаете точное Колмогоровское приближение. Это первый шаг. Утверждение носит название теоремы ... . 

Второй вопрос представлялся существенно более болезненным. Примерно в одно время с Колмогоровым было показано, что если мы потребуем от функции не только непрерывность, но еще и аналитичность (сильная гладкость), то утверждение Колмогорова-Арнольда неверно. Возникает естественный вопрос: имеет ли это практическое применение?

//Если ряд тейлора сходится к самой функции, то она аналитична

Для наших целей, а именно для построения полной бифуркационной картины этот спор не важен по одной причине: если мы рассмотрим множество всех функций $chi_i$, которые фигурируют в представлениях и рассмотрим те функции $chi_i$, которые не просто фигурируют в представлении функции $u$, но фигурируют в представлении тех функций, которые являются решениями наших ОДУ, то поскольку функция $u$ дифференцируема, то дифференцируемыми являются все функции $chi_i, phi_j$. 

... представляют собой предел некоторого итерационного процесса. На каждом шаге этого итерационного процесса мы знаем значения этих функций в конечном числе точек, а потом мы можем считать их гладки ми в той степени, в которой нам захочется. Посколько мы являемся прикладными математиками, то мы в общем-то всегда имеем дело с функциями из численных методов, соответственно, с функциями известными в конечном числе точек. С формальной точки зрения здесь нет никакого противоречия. Однако с точки зрения вычислительной математики это может приводить к весьма неприятным последствиям, ведь численно удерживаться на этом подмногообразии функций нам не удастся, мы все время соскакиваем и оказываемся с численной точке зрения в заборах, wild functions, что затрудняет численный счет. Некие результаты в этой области были получены. 

#pagebreak()

Нам понадобится еще одно следствие из теоремы Колмогорова-Арнольда о суперпозиции. Уже в 21-ом столетии Rauf Doss доказал очевидное следствие: 

$ u(x_1, dots, x_n) = sum_(i = 1)^(2n + 1) chi_i (product_(j = 1)^n phi_j(x_j)) $

В этой ситуации мы получаем произведение. Из этого утверждения получаются два следствия, рассмотрим их в терминах функции от двух переменных (для упрощения)

$ u(x,y) = sum_(i = 1)^5 chi_i (phi_1 (x) dot phi_2 (y)) $

1) Давайте разложим эту функцию в ряд Тейлора в окрестности нуля (можем и в окрестности любой заданной функции, но сделаем в окрестности нуля, так как для любой сложной системы существует решение близкое к нулю, в физике это, например, термодинамическая ветвь):

$ approx sum_(i = 1)^5 chi_i (0) + sum_(i = 1)^5 chi'_i (0) dot phi_1(x) dot phi_2 (y) $

Получаем метод Кантаровича. Чем больше слагаемых удержите, тем точнее будет аппроксимация. Ничего нам не мешает обобщить Итерационный Обобщенный метод Кантаровича. Не будем ничего расскладывать в ряд Тейлора. Будем работать с изначальной, точной, формулировкой. Но тогда мы имеем суперпозицию функций от одной переменной, просто они более сложные. 
$ u(x,y) = sum_(i = 1)^5 chi_i (z) (phi_1 (x) dot phi_2 (y)) $

$chi_i (z)$ являются функциями одной переменной. Если мы применим логику ИОМК и будем отыскивать в рамках аналогичного итерационного процесса и phi_1 (x) и phi_2 (y) и chi_i, то мы получим на каждой итерации такого процесса разрешающие соотношения для вышеуказанных функций одной переменной, причем эти разрешающие соотношения будут представлять собой краевые задачи для ОДУ, которые мы знаем как решать. 

#pagebreak()

_Замечание_. Самое важное, что следует подчеркнуть: в независимости от того какую формулировку теоремы Колмогорова-Арнольда мы выберем и какой метод, аналогичный ИОМК мы не построим, мы все равно получаем какое-то последовательное применение метода Ньютона для решения каких-то краевых задач для ОДУ.

Соответственно, вся теория фиксации точки бифуркаций, определение их типа, отыскание исходящих из них ветвей решения, соотнесение с теорией катастроф, построение полной бифуркационной картины получается естественным образом. Для одномерного случая мы это просто знаем. А в случае многих переменных через различные формулировки теоремы Колмогорова-Арнольда все сводится к функциям от одной переменной. Таким образом мы получаем базовую задачу, а именно решение задачи построения полной бифуркационной картины для нелинейных уравнений в частных производных, данной постановки задачи. Именно к этому классу .... относится машинное обучение. Соответствующие разделы машинного обучения являются некой численной аппрокисмацией соответствующего непрерывного случая. 

_Замечание_. Мы говорим о вариационных постановках. Пробелма заключается в том, что, зачастую, дифференциальная постановка задач машинного обучения встречаются производные нечетных порядков. 

$ (d P)/(d t) (x,t) $
Мы не можем ничего проварьировать, для решения такой постановки. Решение было найдено тремя немецкими математиками Jordon, Kinderlehrer, Olto, JKO. Идея заключалась в достаточно простой вещи: на том месте, функциональная вариация которого должна давать нам производную, должен стоять объект, который при вариации дает аппроксимацию данной производной. Разностная вариация. 

$ (-u(x, t - Delta t) + u(x,t))^2/(2h) $

При этом формально мы считаем что при движении по времени, координате $t$, мы имеем наши вариационные постановки, определенные на малых, конечных промежутках времени длины $Delta t$. Тогда приступая к поиску функции на промежутке $(t, t + Delta t)$, мы уже знаем функцию $u(x, Delta t)$, она не подлежит варьированию на этом промежутке. Следовательно, вариация такого выражения даст нам $ (u(x,t) - u(x, t - Delta t))/h $

Что близко к производной $(d u)/(d t).$ Погрешность такого приближения: $O(Delta t)$. Делая его малым, мы получаем вариационную постановку, к которой можно применять ИОМК. Это та идея, которую предложили JKO. 

Не обязательно рабски следовать их идее. Мы можем ввести соответствующее слагаемое функционалом, формально, и просто его варьировать. Тогда в результате вариации мы получим, соотвестсвенно, не ОДУ, но так называемые дифференциальные уравнения с задержкой. Это класс дифференциальных уравнений, в которых кроме самой функции и ее переменных так же фигурируют функции, зависящие не от времени $t,$ а от времени $t - a,$ где $a-$ фиксированная константа.

Если мы говорим о сильном искусственном интеллекте, то мы говорим о умении перехода между состояниями ... 

Эти переходы с математической точки зрения дают нам теорию биффуркаций для нелинейных ОДУ, выраженных вариационной постановкой. 

Применение ИОМК позволяет нам строить бифуркационные картины и заниматься решением как прямых, так и обратных задач и задач управления. 