= Лекция 18. Завершение прогнозирования за горизонтом прогнозирования. 

Напомним, что базовой задачей является не просто научиться прогнозировать на один или несколько шагов вперед, но научиться прогнозировать на много шагов вперед. Собственно говоря, на число шагов, сопоставимое или превышающее горизонт прогнозирования. На один шаг могут прогнозировать практически любые модели, но на много шагов вперед ни одна из них прогнозировать не может. 

Введение шаблонов прогнозирований уже позволяет прогнозировать на несколько шагов вперед для того, чтобы как-то сдвинуться с этой мертвой точки экспоненциальной ошибки.

Разумеется, это является неким полиотитом, и мы в любом случае должны использовать стандартную стратегию при прогнозировании на много шагов вперед, а именно стратегию прогнозирования по уже спрогнозированным точкам. Если мы закончили наблюдать в ряд на какой-то точке и получили прогноз для следующей точки, то это прогнозное значение мы можем считать истинным и использовать, прогнозировать уже с учетом этого значения. Тем самым мы, теоретически, можем двигать наш прогноз до бесконечности. 

Когда мы говорим "стандартную стратегию", надо ясно понимать, что существует очень много разных подходов организовать прогнозирования, и такой наивный подход "точка-за-точкой" не самый лучший и не самый эффективный. Но как бы там ни было никакая из стратегий и никакой из методов прогнозирования не решает нашей базовой проблемы -- экспоненциального роста ошибки с числом шагов вперед, на которое мы хотим спрогнозировать. Значит нужно придумать что-то еще. Прорывной оказалась следующая идея:

Идея непрогнозируемых точек. Использование шаблонов в прогнозировании позволяет получить для каждой точки, для которой мы хотим отыскать прогноз, некоторое, обычно весьма значительное число возможных прогнозных значений. Мы ввели понятие $hat(S)_(t + k),$ как множество возможных прогнозных значений для точки, которая стоит на $k$ позиций вперед во временном ряду от точки конца наблюдений $t$. Раз у нас есть множество возможных прогнозных значений, то мы можем задасться вопросом, можно ли получить некий возможный прогноз, исходя из этого множества возможных прогнозных значений. 

Если у вас есть тысяча возможных прогнозных значений, где, условно, 500 значений лежит компактно у $+1$, а еще 500 у $-1$, то стандартные методы вроде "усреднить" ведет нас середину, в 0, что прогнозным значением являться не может.

Другая ситуация, когда ножество возможных прогнозных значений размазано вдоль всего допустимого промежутка и никакой кластерной структуры выделить нельзя.

Хорошая ситуация, когда все точки сконцентрированы вокруг какого-то значения, и, соответственно, мы можем получить некий разумный алгоритм получения единого прогнозного значения. Эта идея привела к тому, что мы для ножество возможных прогнозных значений вычисляем две функции:

Функцию прогнозируемости $xi(hat(S)_(t + k)) : cases(
  1", если мы можем получить единое прогнозное значение",
  0", иначе"
)$

Вторая функция -- единое прогнозное значение $hat(y)_(t + k) = hat(y)(hat(S)_(t + k))$. 

Такой подход мгновенно превращает классическую постановку задач прогнозирования как задачи однокритериальной оптимизации (один критерий качества) в неклассическую постановку, двухкритериальную оптимизацию.

Первый критерий -- хотим минимизировать ошибку на прогнозируемых точках: $ I_1 = sum_(t in T) xi(hat(S)_(t + k)) M [y_(t + k) - hat(y)_(t + k)]^2 -> min $

И второй критерий: хотим минимизировать количество непрогнозируемых точек:

$ I_2 = sum_(t in T) [1 - xi(hat(S)_(t + k))] -> min $

Надо ясно понимать, что переход к двухкритериальной задаче оптимизации это всегда некоторое усложнение, тем более даже не на алгоритмическом уровне построения эффективного метода решения, сколько на уровне концептуальном. Очевидно, что существуют решения, которые будут хуже по первому критерию и лучше по второму, или наоборот. 

В теории многокритериальной оптимизации вводится множествонеухудшаемых решений Парето. Так же фронт Парето. Некое множество, такое, что выход за его пределы является либо недопустимым, либо хуже по одному из кретериев.

#grid(
  columns: (0.8fr, 1fr),
  [
    #image("../images/lecture_18_images/image1.png", width: 90%)
  ],
  [
    Решения, которые выходят на фронт Паретта, это те решения, которые являются несравнимыми между собой. Если мы возьмем любые два произвольных решения, из множества Парето, то одно из них будет лучше по первому критерию, другое по второму. Это некоторая концептуальная сложность, поскольку не очень понятно, какое решение в итоге выбирать. 
  ],
  
)

//отступление про многокритериальную оптимизацию

// марсияне высадились на красной площади и отменили все деньги

В значительном числе случаев мы имеем многокритериальную оптимизацию.  

Важно сказать, что такая постановка задачи привела к возможности решения базовой постановки, а именно нам действительно удаестся прогнозировать за горизонтом прогнозирования. Метафорой можно сказать, что мы пересекаем болота по кочкам. Мы прыгаем от одной прогнозируемой точки к другой, игнорируя непрогнозирования точки.

Таким образом нам удалось заскочить далеко за горизонт прогнозирования, в то время как классические алгоритмы тонут в непрогнозируемых точках. Так мы сформулировали задачу как задачу двухкритериальной оптимизации. Но это лишь формулировка задачи. По сути выдвинута лишь гипотеза, а как ее проверить?

Давайте предположим, что у нас есть некий идеальный алгоритм определения непрогнозирования точек, идеальная $xi$. Для тестовой выборки выглядит она достаточно просто. Алгоритм просто обращается к истинному значению и сравнивает с прогнозируемым. Если разница $|y_(t + k) - hat(y)_(t + k)|$ меньше некого $epsilon$, то функция возвращает $1$. Иначе 0. Такой алгоритм назвали Демоном. Он не сообщает истинный алгоритм, лишь говорит, что прогноз сильно или не сильно уклоняется от истинного значения. 

// Сократу демон давал советы в сложные моменты жизни

Так мы получаем идеальную функцию $xi$, но идеальной функции $hat(y)$ у нас все еще нет. 

Для первого критерия нарисуем график. По оси абсцисс будет идти $k$, количество прогнозируемых точек, а по оси ординат будет процент непрогнозируемых точек на тестирующем множестве. 

Для второго критерия отложим среднюю ошибку на теcтирующем множестве $T$.

#grid(
  columns: (1fr, 1fr),
  [
    #image("../images/lecture_18_images/image2.jpeg", width: 100%)
  ],
  [
    \ \ \
    Для классического алгоритма мы получаем экспоненциальную ошибку, а для нашего на прогнозируемых точках ошибка перестала расти экспоненциально, она ведет себя как постоянная функция порядка $k$.

  ],
  
)

Это означает, что задача решена. Мы побили закон Ляпунова, но ценой того, что даем прогнозирование не во всех точках. Для многих задач это подходит, например, торговли на бирже, ведь нам необязательно торговать в каждый момент времени. Но, например, в задаче прогнозирования инфаркта, он может произойти, теоретически, в непрогнозируемой точке. 

// отступление

Мы не сказали главную загвоздку -- вычисление функции $hat(xi)$. Решение такой задачи называется аппроксимацией демона. Так же не совсем понятно как искать $hat(y)$. Множество вариантов можно посмотреть в статье Gromov Baranov 2024.

А пока приведем несколько примеров таких функций:

Пусть у нас есть $hat(S)_(t + k)$. И мы можем их скластеризировать. У нас выделится какое-то количество кластеров, один из которых будет наибольшим. Мы говорим, что если размер максимального кластера больше некоторого порога $sigma: $ $max_i |c_i| >= sigma(90%)$, то достаточно очевидно, что мы можем считать такую точку прогнозированной. Тогда выберем $hat(y)$ как центройд кластера. 

Другой подход. Давайте считать множество возможных прогнозных значений не для одной позиции $t +k$, а для нескольких позиций сразу: $hat(S)_(t + k), hat(S)_(t + k + 1), hat(S)_(t + k + 2), dots$

Если ошибка (разброс) этих значений растет на первых трех шагах, то эту точку уже можно считать непрогнозируемой. Получилось, что он уже не функционирует. 

Еще один подход: давайте брать в рассмотрение не только максимальный кластер, но и, например, второй по размеру кластер. Тогда вместо единого прогнозного значения мы получаем два единых прогнозных значения, из которых стартуют независимые траектории. Если оказывается, что в какой-то момент времени эти траектории пересекаются (достаточно близко сходятся), то речь идет о прогнозируемой точке. В качестве прогнозируемого значения выбирается среднее. При этом необязательно длить все эти траектории, ведь их будет очень много. 

На этом мы остановимся, исследования еще не завершены и подробности вызодят за границы этого курса. 

Какие здесь есть открытые вопросы? Пусть у нас есть множество Парето, и если мы будем брать разные способы оценки двух функций, будем попадать в разные точки фронта Парето. Но проблема в том, что мы можем лишь по имеющимся подходам находить точки, а хотелось бы уметь задавать точку, какой-то порог выполнения двух критериев, и получать алгоритм получения таких значений. Но такого алгоритма пока не существует. Другой вопрос, как далеко можно прыгать по точкам, как далеко можно уйти за предел прогнозирования? Неизвестно. Можно ли как-то заполнить непрогнозируемые точки? Оптимального решения нет.
