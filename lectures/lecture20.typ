= Лекция 20. 

Хотим, чтобы некоторые теоретические стали более практическими. Наша главная цель понять, удовлетворяет ли теоретическая модель следующим требованиям:

1) можем ли мы посчитать?

2) можем ли мы посчитать робасно?

3) можем ли мы посчитать на имеющихся данных?

#align(center, "Выбор параметров реконструкции.")

В независимости от того, какую задачу мы решаем в рамках хаотической динамики, задачу прогнозирования, либо оценку тех или иных характеристик хаотической системы (например размерность аттрактора), возникает базовый вопрос: как оценить те параметры, дефундаментальные параметры хаотической динамики, опираясь на которые мы можем решать указанные задачи.

Эти параметры специфицируются теоремой Таккенса, основной теоремой теории прогнозирования, и всплывают в том или ином виде в любой задаче, которую мы собираемся решать. 

1) $l$ -- размерность $z$-вектора. 

2) Физическое время $Delta t$, которое протекает между двумя последовательными наблюдениями. 

3) $h$ -- измеряемая характеристика. 

Величина $l$ является нашим произволом, мы можем менять ее, как нам захочется. Величина $Delta t$ является частичным произволом, в некоторых случаях мы можем ее менять, например, при прогнозировании финансовых рядов, а в некоторых не можем, например, если прибор тарирован на определенную частоту. Задача $h$, оптимальные наблюдения, и в такой трактовке ее никто не решал. Обычно меряется то, что меряется. Если прибор предназначен для определенной величины, другую измерить мы не можем. Так что для изменения $h$ у нас еще меньше степеней свободы. Не всегда ясно, какая характеристика оптимальна. 

Мы ограничимся измерением $l$ и $Delta t$.

При оптимальном выборе $l$ существует две проблемы: $l$ слишком мало, либо слишком велико. (в сравнении с истинной размерностью пространства)

В первом случае мы "комкаем" истинное пространство, и делаем участки ряда, которые не должны быть близки друг к другу, близкими, что затрудняет и реконструкцию аттрактора, и прогнозирование, и все остальное.

Во втором случае происходит обратный эффект. Для борьбы с этими двумя ситуациями было предложено два подхода. Первый носит название Ложных ближайших соседей (FNN, false nearest neighbours), второе ложных ближайших соседей на складках (FNF, false nearest neighbours on folds). 

Если мы рассматриваем $z$-вектора размерности $k$, то мы с удивлением обнаруживаем, что если 2 $z$-вектора близки в этом пространстве, то близкими должны быть и их удлинения в пространстве $z$-векторов размерности $k+1$.

$ rho(z_1^((k)), z_2^((k))) < epsilon => rho(z_1^((k+1)), z_2^((k+1))) < epsilon $

Утверждается, что если 2 $z$-вектора близки, то и их удлинения будут близки. Можно формально сослаться на дифференцируемость отображения $lambda,$ которое доказывается теоремой Таккенса. 

//свойство либшевости 

В ситуации, когда это требование нарушается, мы говорим, что $z_1^((k)), z_2^((k))$ являются ложными случайными соседями, и их близость является случайностью, вызванной некорректностью реконструкции истинной динамики. 

Таким образом, этот метод дает прекрасный способ оценки оптимальной размерности $z$-вектора. Мы итерируемся по размерности $k$ с разумным шагом и считаем значение количества ложных соседей как функцию от размнерности $k$.

Эта величина позволяет построить график

#image("../images/lecture_20_images/image1.jpg")

В какой-то момент у нее наблюдается резкое падение числа ложных соседей. Момент, когда мы получаем такое падение, считается оптимальным значением размерности, то самое $l$.

Очевидно, что у нас выполнены условия теоремы Таккенса, с другой стороны от ситуации с ложными соседями на складках мы далеки. 

Замечание. Нужно понимать, что число ложных ближайших соседей никогда не станет нулем, с другой стороны, такая модель хорошо работает на всех модельных рядах. На реальных рядах работает не всегда хорошо, но всегда стоит ее рисовать, чтобы сделать какое-то рациональное рассуждение о размерности. Либо сказать, что система слишком сложна для классических алгоритмах.

Далее поговорим о $Delta t$.

$ w = (l - 1)Delta t $

$w$ носит название ширины окна реконструкции. В реальных задачах именно она является тем единым параметром, с которым стоит работать.

Рассмотрим $z(t)$ как функцию от времени, и его компоненты будем считать центрированными относительно его середины. Будем полагать следующее

$
  z(t) = {x(t + (alpha w)/2)}
$
Где $alpha in [-1, 1]$. Самым левым значением будет $x - w/2, $ самым правым $x + w/2$, остальные равномерно распределены между ними. 

Давайте разложим $z(t)$ в ряд тейлора относительно точки $t$.

$
  z(t) = sum_(k = 0)^K 1/(k!) e_k (w/2)^k alpha^k (t) + o(...)
$

Где $e_k$ -- вектор, составленный из значений $alpha$ в $k$-ой степени. Если мы ортогонализируем систему векторов $e_k$, результатом ортогонализации будет новая система векторов $nu_k$, в которой 

$
  z(t) = sum_(k = 0)^K A_k nu_k
$

Где $nu_k$ -- вектора новой, ортонормированной системы векторов, а $A_k$ -- соответствующие коэфициенты. Если мы внимательно посмотрим на новую систему ортонормированных векторов, окажется, что она является системой интерполированных полиномов Лежандра ....

Можно показать, что коэфициенты $A_k$ могут быть приближенно описаны как 

$
  A_k approx integral_(-1)^1 x(t + w/2) P_k (alpha) d alpha
$
$
  P_k (alpha) = (partial^k/(partial x^k))[(1-alpha^2)^k]
$

$k$-кратно интегрируя по частям это выражение, ..., мы получим следующее выражение:

$
  A_k = (-1)^k alpha^k (w/2)^k integral_(-1)^1 x^((k)) (t + w/2) (1 - alpha^2) " " d alpha
$

Заменяя $k$-ую производную под интегралом на ее значение в некоторой точке $x^((k)) (t^*),$ мы получаем следующую конструкцию:

$
  A_k = (-1)^k x^((k))(t^*) integral_(-1)^1 (1-alpha
  ^2) " " d alpha
$

Полиномы Лежандра по построению, и сам переход к ортонормированной системе, дают нам Анализ главных компонент (PCA). .................

Когда мы переходим к векторам $nu_k$, мы получаем ситуацию, похожую на анализ главных компонент. Базис Каронама-Лоеба (Loeve, ...). Если мы предполагаем, что ситуация с анализом главных компонент выполнена, то для какого-то числа $k$ разбросы вдоль направлений $nu_k$ должны быть существенно меньше, чем разбросы вдоль других направлений. 

Тогда оценкой $w$ можем считать такую ситуацию:

$
  hat(w): sigma(A_1) = sigma(A_2)
$

Иначе говоря:

$
  sqrt(12) " " sigma(x(t)) = sigma((d x)/(d t))
$

Мы увеличиваем величину $w$ в неких разумных пределах и ждем, когда для соответствующего пространства $z$-векторов, будут достигнуты данные условия. Тогда будем считать $w$ оптимальным. Оценка очень грубая. Но других нет.

#align(center, "Размеры выборок.")

Еще одним ограничением при работе с хаотическими системами и рядами является размер выборки, длина ряда, которую мы должны использовать, чтобы получить сколько-нибудь адекватные значения параметров. 

......

Некоторой реперной точкой в хаот рядах является ограничение $10^n$ -- порядок той величины, которая нам нужна для адекватного прогнозирования, адекватного восстановления характеристик временного ряда. Здесь $n -$ размерность странного аттрактора той динамической системы, которая этот ряд породила. $n$ может быть достаточно большим числом. Если в случае с канторовым совершенным множеством мы получали красивое $n$ порядка единицы, то в случае, например, финансовых рядов, $n ~ 11-12$. Кроме того, нужно понимать, что $10^n$ является грубой оценкой снизу. 

В случае канторова совершенного множества мы вряд ли сможем спрогнозировать погодный ряд по 10 точкам. Эта ситуация ставит некоторую проблему возможности реально прогнозировать, реконструировать систему со сложным аттрактором. Ситуация $n = 10$ -- реально сложная система. Однако большинство сложных систем является не настолько сложными. 

Даже в той ситуации, когда данному ряду не хватает длины, мы можем использовать для его прогнозирования не только сам этот ряд, но некоторое множество похожих на него рядов. Если мы хотим прогнозировать погоду вокруг Вышки, можно взять данные не только с ближайшей метеостанции, но и данные какой-то окрестности Москвы. Такие данные дадут больше информации о паттернах погоды. В подавляющем большинстве ситуаций возможно добрать количество наблюдений, беря похожие ряды. Но что значит похожие ряды?

// разговор про прогнозирования инфаркта, информация о сердцебиении с apple watch похожих людей

Популярный метод -- DTW(Dynamical Time Warping), но работает не всегда. Можем сказать, что похожие ряды -- те, которые улучшают прогнозирование. Проблема открытая. Какие наблюдения мы можем подмешивать, чтобы эффект увеличения длины ряда был положительным. 


