= Лекция 15. Энтропия Колмогорова-Синая.

Начали изучаение хаотических систем, ввели старший показатель Ляпунова. Ввели понятие Ляпуновского спектра и старшего показателя Ляпунова как его максимального значения. Все значения спектра носят название линейных показателей Ляпунова, потому что они зависят лишь от одной траектории линеализированной системы. Кроме линейных(одномерных) показателей Ляпунова существуют еще объемные, или многомерные показатели Ляпунова, которые определяются следующим образом:

$ kappa_m = lim_(t -> infinity) 1/t ln sqrt(det(mat(u_11 (t), "", u_(m 1) (t); dots.v, dots.down, dots.v;
u_(1 n) (t), "", u_(m n) (t) )))  $

Матрица, фигурирующая в определении составлена из столбцов, которые представляют собой линейно независимые решения линеализации исследуемой системы. Теория говорит нам, что их $n$ штук, но в данном случае $m < n$. Для одномерного, линейного, случая, так называемого случая общего положения, является ситуация $lambda = lambda_1$ и мера тех начальных условий в пространстве $RR^n$, с которых мы можем достигнуть других элементов Ляпуновского спектра, равна нулю. Соответственно, для объемного показателя ляпунова таким значением $lambda_j = kappa_j - kappa_(j - 1)$. .........

_Замечание_. Это дает нам способ вычисление всего Ляпуновского спекта. Достаточно сказать, что ...

$ kappa_m = lambda_1 + dots + lambda_m $

Особый интерес представляет случай $m = n$. В этой ситуации матрица представляет собой так называемый определитель Вронского -- Вронскиан. Нам важно не это, а что при $m = n$ объемный показатель Ляпунова дает нам фундоментальную классификацию всех систем на диссепативные и консервативные. 

Все системы в мире делятся на две категории: диссепативные и консервативные. 

Консервативные системы (от лат. консерватио -- сохраняют) это системы, в которых выполняется один или более законов сохранения, например закон сохранения энергии.

Диссепативные системы (от лат. диссепатио -- рассеивает) это системы в которых все законы сохранения нарушается. Консервативные системы являются каким-то допущением, но нам легко с ними работать. Есть значительная часть реальных систем, которые нам удобно считать консервативными, в которых мы можем принебресь диссепативными эффектами. Однако следует явно понимать, что есть системы, где диссепативные эффекты принципальны. (например теория самоорганизации, которая строится на том, что нарушаются ......, по сути это теория диссепативных систем)

Для консервативных систем $kappa_m = 0.$

Для диссепативных систем $kappa_m < 0$, что дает нам некую характеристику. 

Энтропия Колмогорова-Синая, или почему хаотические системы производят информацию. Мы установили, что все хаотические системы порождают множество траекторий, неустойчивых по Ляпунову. Мы не можем работать с этими траекториями, соответственно, и с этими системами так, как бы мы работали с обычными детерменированными системами, например теми, что описываются системами ОДУ. 
// принцип неопределенности герцена-чернышевского

Достаточно долгое время было непонятно, как работать с такого рода системами. Однако в 60-е годы прошлого столетия Колмогоров предложил, что, несмотря на то, что они полностью детерменированные, рассматривать их как системы вероятностные и работать не с отдельными траекториями, а с некоторыми распределениями, порождаемыми этими системами и с некоторыми понятными нам характеристиками (математическим ожиданием, дисперсией, и подобным).

.............
Если мы будем продливать траекторию в квадрате бесконечно, мы сможем ....

Устремив $t -> infinity$, а $epsilon$, диаметр квадрата, стремится к нулю, тогда мы получаем некоторую вероятностную меру, которая называется инвариантной мерой некоторой динамической системой. Будем обозначать ее буквой $mu$. Такая инвариатная мера для хаотических систем будет сингулярной, не непрерывной, не дискретной, и не их комбинацией. Но все еще будет вероятностной мерой. Более того, можно показать, что она существует для любой системы, в частости для любой хаотической системы. Последнее утверждение носит названия теоремы Крылова-Боголюбова.

Раз у нас есть вероятностная мера (не связана с теорией вероятности, но интеграл по области равен единице, более того, это мера является единственной подлинной характеристикой такой системы), значит мы можем вычислить некоторые привычные нам характеристики этой меры. 

Первой характеристикой является энтропия динамической системы, или энтропия Колмогорова-Синая. 
#pagebreak()
Давайте рассмотрим фазовое пространство нашей динамической системы и разобьем его на непересекающиеся подмножества $A_1, A_2, dots, A_n$ и обозначим их совокупности $A_i_1$. Теперь рассмотрим множество с двумя индексами $ A_(i_1 i_2) = A_i_1 inter f^(-1)(A_i_2) $

Где $x_(i+1) = f(x_i), f: RR^n -> RR^n$.

По индукции строим множество $ A_(i_1, dots, i_k) = A_i_1 inter f^(-1)(A_i_2) inter dots inter f^(-k + 1) (A_i_k) $

Рассмотрим следующее выражение:

$ H_k = sum_(i_1, dots, i_k) mu(A_(i_1, dots, i_k)) ln mu(A_(i_1, dots, i_k)) $

Тогда энтропия Колмогорова-Синая определяется как:

$ K S = lim_(epsilon -> 0) lim_(k -> + infinity) [H_(k + 1) - H_k] = lim_(epsilon -> 0) lim_(k -> + infinity) H_k slash k $
//перепроверить

Для хаотиеческих систем $K S > 0$.

Для регулярных систем $K S = 0$.

По сути это та скорость, с которой растет информация. 

*Прогнозирование за горизонтами прогнозирования*. Рассмотрим временной ряд $y_1, dots, y_n in RR^n$ и поставим цель решить для него задачу прогнозирования, которая формулируется следующим образом:

$ M[y_(t+k) - hat(y)_(t+k)]^2 -> min $

и разобьем его на отрезки длины $s$. В теории их называют z-вектора, а на жаргоне -- чанки (chunks). $s - $ достаточно небольшая величина. 

$ z_0 = (y_0, y_1, dots, y_(s-1)) $
$ z_1 = (y_1, y_2, dots, y_(s)) $

$ z_s = (y_i, y_(i+1), dots, y_(i + s - 1)) $

Длина этого вектора -- фундоментальная характеристика. Сделаем отступление и поговорим про теорему Таккенса (Takens), или основная теорема теории прогнозирования. Мы сказали, что наблюдаемая динамика является траекторией некоторого неизвестного ОДУ $accent(x, dot) = f(x)$. ..... траектории этой системы движутся в окрестности некоторого аттрактора, геометрического центра точек. Поскольку сам объект сложный, мы получаем сложную систему. Называются они странные аттракторы, некоторая фрактальная система. 

Пусть у нас есть размерность аттрактора $n$, тогда мы можем вложить такую траекторию только в объекты размерности $d >= 2n + 1$. Это теорема Уитни (Whitney). 
...

//рогатая сфера александра
//мордель брот -- фрактальная геометрия природы

Таккенс дал ответ на этот вопрос. Если мы от рассмотрения временного ряда перейдем к рассмотрению пространства z-векторов, то выбирая размерность z-векторов достаточно большим, мы можем добиться того, чтобы у нас ... взаимнооднозначное между  и динамикой z-векторов, которая нам прекрасно известна. 

Пусть есть многообразие $M^n$, по которому протекает движение истинной системы, которую мы не знаем. 

_Замечание._ Вообще говоря странные аттракторы хаотических систем не являются многообразиями даже локально. Но мы можем считать что $M^n$ является минимальным иннерционным многообразием, проще говоря, минимальным многообразием, который объемлет странный аттрактор. Можем считать для простоты, что мы работаем именно с многообразием. 

Пусть есть так же отображение $h: M^n -> RR^d$, будем называть его наблюдаемой.... Тогда теорема Таккенса формулируется следующим образом: Если:

1) многообразие $M^n$ и отображение $h$ являются как минимум дважды дифференцируемыми

2) $h(M^n)$ является диффиоморфизмом, взаимно непрерывным и взаимно дифференцируемым отображением

3) выполнены условия теоремы Уитни $d >= 2n + 1$, то есть с топологической точки зрения $h$ является вложением в ...

4) некоторые технические условия

Тогда существует взаимнооднозначное отображение между динамикой истинной системой и динамикой в пространстве z-векторов. 

Пусть есть набор $d$-мерных точек. Пусть $tau -$ физическое время, которое протекает между нашими наблюдениями. Соответственно, в силу того, что $h$ является диффиоморфизмом, отображение $h^(-1)$ отоброзит точку этого ряда в точку на неизвестной нам траектории. Обозначим координату $z_i$ как $x_i$. Обозначим .... как $g^tau$, тогда $x_(i+1) = q^2 x_i ->^h z_(i+1),$ то есть получаем сдвиг временного ряда на $tau$. 

........

#pagebreak()

Опишем все сказанное математически. 

$ z_(i+1) = h(g^tau (h^(-1)(z_i))) $

Обозначим такое сквозное отображение как $Lambda(z_i)$. Согласно теореме Таккенса такое отображение является дифференцируемым. 

$Lambda: z_i -> z_(i + 1)$, хотим оставить только однц компоненту. 

$y_(i+1) = zeta_n (y_i, y_(i - 1), dots, y_(i - d + 1))$. Выходим, мы можем прогнозировать. ....................





