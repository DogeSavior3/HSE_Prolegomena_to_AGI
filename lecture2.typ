#set text(font: "New Computer Modern", lang: "ru")
= Лекция 2. Свойства сложных сетей.

Первое свойство носит название гигантской связанной компоненты.

Наблюдение за реальными сложными сетями указывает, что они не просто эволюционируют (меняют количество ребер и вершин) но и имеют тенденцию к росту. Это позволило применить к ним классический прием естественно научного исследования, который носит название "переход к термодинамическому пределу" или "континуализация". А именно мы исследуем что происходит с объектом, если число составляющих его элементов (в данном случае вершин графа) стремится к бесконечности.

Мы, разумеется, понимаем, что реальные сложные сети конечны, но вместе с тем, мы предполагаем, что, начиная с некоторого большого $N$, мы можем говорить о некоторых асимптотических свойствах, то есть, начиная с некоторого достаточно большого $N$ сложная сеть будет сохранять те же свойства, что и сеть, обладающих "бесконечным количеством вершин".

Здесь было установлено, что для всех сложных сетей мы наблюдаем несвязанность сложных сетей как графов. Сложные сети состоят из некоторого (иногда достаточно большого) количества несвязанных компонент. Но вместе с тем, из этих компонент выделяется одна, число вершин в которой по порядку совпадает с числом вершин во всем графе.

$ N_(G C C) = O(N), N -> infinity $

В случае неориентированных графов, мы должны модифицировать понятие гигантской связанной компоненты. Она разбивается на четыре составляющих:

1) Гигантская сильно связанная компонента. Здесь предполагается, что из любых вершин $i$ и $j$ мы можем достигнуть из вершины $i$ вершину $j$, из вершины $j$ вершину $i$.

2) Гигантская выходная компонента. Это множество вершин, в которые мы можем попасть из вершин гигантской сильно связанной компоненты. 

3) Гигантская входная компонента. Это множество вершин, из которых мы можем попасть в вершины гигантской сильно связанной компоненты.

4) Так называемые усы, специальная структура, которая представляет собой линейно упорядоченную последовательность вершин, исходящих из гигантской сильно связанной компоненты.
#pagebreak()
Более того, возвращаясь к неориентированным графам, мы получаем, что для характеризации сложных сетей мы должны ввести свойство его разреженности. Традиционно, разреженность графа характеризуют как отношение фактического числа ребер к максимально возможному.

$ rho = E/((N(N-1)) slash 2) $

При этом, мы пользуемся той же идеей перехода к термодинамическому пределу, мы смотрим, как ведет себя величина $rho$ не для данной конкретной сложной сети, но для последовательности сетей, с увеличивающимся размером, при $N -> infinity$.

Очевидно, что если граф полносвязный, или близкий к полносвязному (неразреженный), тогда величина $rho$ будет вести себя как $O(1)$, поскольку $E ~ O(N^2)$.

С другой стороны, если мы имеем дело с чем-то вроде минимального остовного дерева, где $E ~ O(N),$ то $rho -> 0$. Если мы будем наблюдать промежуточную ситуацию, где $E -> O(N^alpha), 1 < alpha < 2,$ то мы говорим о разреженном графе.

Все сложные сети являются разреженными графами. 

Второе свойство носит название Малого мира.

Путем между вершинами $i_0$ и $i_n$ называется последовательность ребер $(i_0, i_1), (i_1, i_2), dots, (i_(n-1), i_n)$ такая, что первое ребро инцидентно вершине $i_0$, а последнее вершине $i_n$. Кратчайшим путем между вершинами $i_0$ и $i_n$ является путь, содержащий минимальное число ребер. Далее, на основании этих конструкций мы должны построить некоторые характеристики, которые характеризуют не отдельную пару вершин, но граф в целом. А именно:

1) Диаметром графа называется максимальный из путей, где $l_(i,j)$ -- длина кратчайшего пути, соединяющего вершины $i$ и $j$

$ d_G = max_(i != j) l_(i j) $

2) Эксцентриситетом вершины $i$ мы будем называть максимальную длину кратчайшего пути, соединяющий вершины $j$ и $k$, не проходящей через вершину $i$

$ e c(i) = max_(i != j) l_(i,j) $

3) Тогда радиусом графа G будет минимальный эксцентриситет.

$ r_G = min_i e c(i) $
#pagebreak()
4) Самое ходовое и самое эффективное на практике -- средняя длина кратчайшего пути в графе

$ < l > = 1/(N(N-1) slash 2) sum^N_(i != j) l_(i j) $

Если мы наблюдаем что-то вроде полносвязности ($< l > "" ~ O(1)$) -- это простая сеть.

Если мы возьмем что-то похожее на кристалическую решетку, это тоже будет простая сеть порядка $O(n^(1 dot d)),$ где $d$ -- размерность.

Оказалось, что если расстояние ведет себя как $O(n^(beta)),$ то речь идет о какой-то вариации простой сети.

Классическим примером сложной системы являются системы, у которых среднее расстояние -- это величина порядка логарифма числа вершин.
$ < l > "" ~ O(ln N)  $

Для реализации такого рода системы нам необходимо существование специальных вершин -- хабов, которые характеризуются тем, что через них проходит много кратчайших путей, эти вершины обеспечивают связность графа.

В отношении хабов, как всегда в математике, мы можем ставить две задачи:

1) Отыскание, обнаружение. Это прямая задача теории хабов.

2) Обратная задача, которая заключается в конструировании сети таким образом, что удаление даже значительного числа его хабов не приводит ни к потери связанности, ни даже к нарушению нормального функционирования сети, протекания потоков.

Если для сети выполняется такое свойство (свойство 2), то мы будем говорить, что сеть структурно устойчива (resilent). В настоящее время именно организация структурно устойчивых бесхабовых сетей является одной из наиболее значимых.

Все задачи в математике делятся на три больших класса:

1) Прямые задачи, есть некоторое описание реального процесса, структура, уравнение и подобное. 

2) Обратные задачи, имеется некоторое множество наблюдений реального процесса, мы пытаемся по этим наблюдениям восстановить процесс, который имеет место в реальном мире.

3) Задача управления -- имеется возможность каким-то образом воздействовать на объект, с которым мы работаем, и мы должны добиться того, чтобы наше воздействие приводило к желательному результату.


